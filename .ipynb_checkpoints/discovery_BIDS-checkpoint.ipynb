{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "from glob import glob\n",
    "import shutil\n",
    "import json\n",
    "import nibabel as nib \n",
    "import numpy as np \n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: \n",
    "\n",
    "accomodate ses-0 \n",
    "\n",
    "fix ses-010 bug \n",
    "\n",
    "jupytext it! \n",
    "\n",
    "sessions languishing in unsorted\n",
    "\n",
    "more helpful prints -> log files \n",
    "\n",
    "better metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plan:\n",
    "\n",
    "check if subject/session folder already exists \n",
    "\n",
    "~~1. create session function~~\n",
    "    a. accomodate weird s43 session \n",
    "\n",
    "~~1. copy bold scans~~\n",
    "~~s2. rename bold scans\n",
    "\n",
    "~~1. copy anats \n",
    "~~2. rename anats~~\n",
    "~~3. deface \n",
    "\n",
    "~~1. meta data - done for now (copied from heudiconv), but could be done here too. \n",
    "\n",
    "~~DOWNLOAD REST OF SCANS\n",
    "\n",
    "RUN FMRIPREP\n",
    "\n",
    "\n",
    "BIDS\n",
    "\n",
    "\n",
    "\n",
    "extras: \n",
    "1. copy dwi \n",
    "2. rename dwi\n",
    "\n",
    "1. copy fmaps \n",
    "2. rename fmaps\n",
    "\n",
    "1. tally \"extras\" \n",
    "2. report \"missing\" scans \n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OAK = '/oak/stanford/groups/russpold'\n",
    "#mounted OAK \n",
    "OAK = '/Users/work/Analysis/network_fmri/OAK'\n",
    "\n",
    "raw_dir = op.join(OAK, 'data/network_grant/nifti_raw_download')\n",
    "\n",
    "BIDS_dir = op.join(OAK, 'data/network_grant/discovery_BIDS')\n",
    "HOME = '/home/users/mphagen/network_fmri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [i.split('/')[-1] for i in glob(op.join(raw_dir, 's*'))] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_subject' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ad08ee1be322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mraw_sub_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msub_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_subject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_sessions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfunc_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_sub_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'*bold/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_subject' is not defined"
     ]
    }
   ],
   "source": [
    "#for testing\n",
    "subject='s43'\n",
    "sessions = [i.split('/')[-1] for i in sorted(glob.(op.join(raw_dir, f'{subject}/*')))]\n",
    "session = sessions[-3]\n",
    "raw_sub_path = op.join(raw_dir, subject, session)\n",
    "sub_path = make_subject(subject)\n",
    "sessions, session_dict = make_sessions(subject, sub_path)\n",
    "func_files = glob.glob(op.join(raw_sub_path, f'*bold/*'))\n",
    "file = func_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_desc_json = {\"Name\": \"Network Grant\", \n",
    "                    \"BIDSVersion\": \"1.5.0\"} \n",
    "\n",
    "dataset_desc_path = op.join(BIDS_dir, 'dataset_description.json')\n",
    "if not op.exists(dataset_desc_path): \n",
    "    print(\"making dataset description\")\n",
    "    with open(dataset_desc_path, 'w') as outfile:\n",
    "        print(\"still making dataset description\")\n",
    "        json.dump(dataset_desc_json, outfile)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('echo_times.json', 'r') as e: \n",
    "    echo_dict = json.load(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_echo_metadata(echo, func_sub_path, subject, session_dict, task):\n",
    "    echo_time = echo_dict[f'echo_{echo}']\n",
    "    scan_echo_dict = {\n",
    "        'EchoTime': float(echo_time),\n",
    "        'EchoNumber': int(echo)\n",
    "    }\n",
    "    echo_json = op.join(func_sub_path, f'sub-{subject}_{session_dict[session]}_{task}_run-01_echo-{echo}_bold.json')\n",
    "    with open(echo_json, 'w') as e: \n",
    "        json.dump(scan_echo_dict,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subject_dirs(subject): \n",
    "    sub_path = op.join(BIDS_dir, f'sub-{subject}')\n",
    "    os.makedirs(sub_path, exist_ok=True)\n",
    "    return sub_path\n",
    "        \n",
    "def make_session_dirs(subject, sub_path): \n",
    "    \"\"\"\n",
    "    will currently put s43s out of order because of their weird session\n",
    "    \"\"\"\n",
    "    \n",
    "    sessions = [i.split('/')[-1] for i in sorted(glob(op.join(raw_dir, f'{subject}/*')))] #look at the source \n",
    "    session_dict = {}\n",
    "\n",
    "    session_dict = {sessions[s]: f'ses-0{s+1}' for s in range(len(sessions))} #vpad \n",
    "    \n",
    "    #create paths \n",
    "    for ses in session_dict.values(): \n",
    "        ses_path = op.join(sub_path, ses)\n",
    "        os.makedirs(ses_path, exist_ok=True)\n",
    "           \n",
    "    with open(f'{subject}.json', 'w') as outfile:\n",
    "        json.dump(session_dict, outfile)\n",
    "    return sessions, session_dict\n",
    "\n",
    "def move_func(subject, session, session_dict): \n",
    "    raw_sub_path = op.join(raw_dir, subject, session)\n",
    "    func_files = glob.glob(op.join(raw_sub_path, f'*bold/*_e*.nii.gz'))\n",
    "    func_sub_path = op.join(BIDS_dir, f'sub-{subject}', session_dict[session], 'func')\n",
    "    os.makedirs(func_sub_path, exist_ok=True)\n",
    "    for file in func_files: \n",
    "        #can change to rename function with dictionary for dual tasks too \n",
    "        task = task_name_fix(file)\n",
    "        echo = file.split('/')[-1].split('.')[0][-1]\n",
    "        bids_func_path = op.join(func_sub_path, f'sub-{subject}_{session_dict[session]}_{task}_run-01_echo-{echo}_bold.nii.gz')\n",
    "        if not op.exists(bids_func_path): \n",
    "            print(f'MOVING {task} {session}')\n",
    "            shutil.copy2(file, bids_func_path)\n",
    "            write_echo_metadata(echo, func_sub_path, subject, session_dict, task)\n",
    "        else: print(f'EXISTS{task} {session}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_dict = {\n",
    "    'stopWDf': 'stopSignalWDirectedForgetting' ,\n",
    "    'stopWFlanker': 'stopSignalWFlanker'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['directedForgetting', 'stopSignal', 'goNogo', 'flanker', \n",
    "         'cuedTaskSwitching', 'spatialTaskSwitching', 'rest',\n",
    "        'nback', 'shapeMatching']\n",
    "\n",
    "\n",
    "def task_name_fix(file):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # task = file.split('/')[-2].replace('task-', '').replace('shapeMaching', 'shapeMatching').replace('_bold', ''.replace('with', 'w')\n",
    "    task = file.split('/')[-2]\n",
    "    if 'task' in task: \n",
    "        task = task.split('-')[-1]\n",
    "    task = task.replace('shapeMatching', 'shapeMaching')\n",
    "    task = task.replace('_bold', '')\n",
    "    task = task.replace('with', 'w')\n",
    "    if 'w' in task: \n",
    "        task = ''.join([i.capitalize() for i in task.split('_')])\n",
    "        task[0] = task[0].lower()\n",
    "    task = dual_dict.get(task, task)\n",
    "    task =  f'task-{task}'\n",
    "\n",
    "    return task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t1w_check(t1w): \n",
    "    \"\"\"\n",
    "    checks for valid t1w\n",
    "    \"\"\"\n",
    "    img = nib.load(t1w)\n",
    "    dim = img.shape\n",
    "    if len(dim) == 3: \n",
    "        return True\n",
    "\n",
    "    #def t1w_check:\n",
    "    #return len(nib.load(t1w).shape)==3\n",
    "    \n",
    "\n",
    "def fix_t1w_raw_path(t1w): \n",
    "    \"\"\"fixes the stupid spaces\"\"\"\n",
    "    no_spaces = t1w.replace(' ', '_')\n",
    "    try: \n",
    "        os.rename(op.dirname(t1w), op.dirname(no_spaces)) #try shutil? \n",
    "    except OSError:  #be more specific \n",
    "        print('already moved')\n",
    "    return no_spaces\n",
    " \n",
    "    \n",
    "def move_t1w(subject, session_dict):      \n",
    "    t1w_files = glob.glob(op.join(raw_dir, subject, '*', '*T1*', '*.nii.gz'))\n",
    "    for t1w in t1w_files: \n",
    "        t1w = fix_t1w_raw_path(t1w)\n",
    "        session = t1w.split('/')[-3]\n",
    "        bids_anat_path = op.join(BIDS_dir, f'sub-{subject}', session_dict[session], 'anat')\n",
    "        if t1w_check(t1w): #if it passes the check \n",
    "            os.makedirs(bids_anat_path, exist_ok=True)\n",
    "            bids_t1_path  = op.join(bids_anat_path, f'sub-{subject}_{session_dict[session]}_run-01_T1w.nii.gz')\n",
    "            if not op.exists(bids_t1_path): \n",
    "                cmd_string = f'bash network_pydeface.sh {t1w} {bids_t1_path}' \n",
    "                print('\\tDefacing & moving...\\n')\n",
    "                p = subprocess.check_output(cmd_string, shell=True, env=os.environ.copy())         \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/users/mphagen/network_download/s29.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ebb34600f4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msub_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_subject_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_session_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmove_t1w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-1a662b82bffe>\u001b[0m in \u001b[0;36mmake_session_dirs\u001b[0;34m(subject, sub_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mses_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{HOME}/{subject}.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/users/mphagen/network_download/s29.json'"
     ]
    }
   ],
   "source": [
    "for sub in subjects:\n",
    "    sub_path = make_subject_dirs(sub)\n",
    "    sessions, session_dict = make_session_dirs(sub, sub_path)\n",
    "    move_t1w(sub, session_dict)\n",
    "    for session in sessions: \n",
    "        move_func(sub, session, session_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:multi-echo] *",
   "language": "python",
   "name": "conda-env-multi-echo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
